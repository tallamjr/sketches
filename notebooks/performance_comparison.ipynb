{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Sketch Algorithms\n",
    "\n",
    "This notebook compares the performance and accuracy of different probabilistic data structures implemented in the sketches library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sketches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison\n",
    "\n",
    "Let's compare the accuracy of different sketch algorithms across various cardinalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(sketch_class, cardinalities, lg_k=12, k=4096):\n",
    "    results = []\n",
    "    \n",
    "    for n in cardinalities:\n",
    "        if 'Theta' in sketch_class.__name__:\n",
    "            sketch = sketch_class(k)\n",
    "        else:\n",
    "            sketch = sketch_class(lg_k)\n",
    "            \n",
    "        # Add n unique elements\n",
    "        for i in range(n):\n",
    "            sketch.update(f\"item_{i}\")\n",
    "            \n",
    "        estimate = sketch.estimate()\n",
    "        error = abs(estimate - n) / n\n",
    "        results.append({'cardinality': n, 'estimate': estimate, 'error': error})\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cardinalities\n",
    "cardinalities = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "# Test different sketch types\n",
    "sketch_classes = [\n",
    "    sketches.HllSketch,\n",
    "    sketches.HllPlusPlusSketch,\n",
    "    sketches.CpcSketch,\n",
    "    sketches.ThetaSketch\n",
    "]\n",
    "\n",
    "accuracy_results = {}\n",
    "for sketch_class in sketch_classes:\n",
    "    print(f\"Testing {sketch_class.__name__}...\")\n",
    "    accuracy_results[sketch_class.__name__] = test_accuracy(sketch_class, cardinalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for sketch_name, results in accuracy_results.items():\n",
    "    df = pd.DataFrame(results)\n",
    "    plt.plot(df['cardinality'], df['error'], marker='o', label=sketch_name, linewidth=2)\n",
    "\n",
    "plt.xlabel('True Cardinality')\n",
    "plt.ylabel('Relative Error')\n",
    "plt.title('Accuracy Comparison of Sketch Algorithms')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Now let's compare the update performance of different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_updates(sketch_class, n_updates=100000, lg_k=12, k=4096):\n",
    "    if 'Theta' in sketch_class.__name__:\n",
    "        sketch = sketch_class(k)\n",
    "    else:\n",
    "        sketch = sketch_class(lg_k)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(n_updates):\n",
    "        sketch.update(f\"item_{i}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        'total_time': end_time - start_time,\n",
    "        'updates_per_second': n_updates / (end_time - start_time),\n",
    "        'estimate': sketch.estimate()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark performance\n",
    "n_updates = 100000\n",
    "performance_results = {}\n",
    "\n",
    "for sketch_class in sketch_classes:\n",
    "    print(f\"Benchmarking {sketch_class.__name__}...\")\n",
    "    performance_results[sketch_class.__name__] = benchmark_updates(sketch_class, n_updates)\n",
    "\n",
    "# Display results\n",
    "perf_df = pd.DataFrame(performance_results).T\n",
    "print(\"\\nPerformance Results:\")\n",
    "print(perf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sketch_names = list(performance_results.keys())\n",
    "updates_per_sec = [performance_results[name]['updates_per_second'] for name in sketch_names]\n",
    "\n",
    "bars = plt.bar(sketch_names, updates_per_sec, color=['blue', 'orange', 'green', 'red'])\n",
    "plt.xlabel('Sketch Algorithm')\n",
    "plt.ylabel('Updates per Second')\n",
    "plt.title('Performance Comparison: Updates per Second')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, updates_per_sec):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01, \n",
    "             f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage Comparison\n",
    "\n",
    "Let's compare the memory footprint of different sketch implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sketch_size(sketch_class, lg_k=12, k=4096):\n",
    "    if 'Theta' in sketch_class.__name__:\n",
    "        sketch = sketch_class(k)\n",
    "    else:\n",
    "        sketch = sketch_class(lg_k)\n",
    "    \n",
    "    # Add some data\n",
    "    for i in range(10000):\n",
    "        sketch.update(f\"item_{i}\")\n",
    "    \n",
    "    # Get serialized size as proxy for memory usage\n",
    "    serialized = sketch.to_bytes()\n",
    "    return len(serialized)\n",
    "\n",
    "memory_usage = {}\n",
    "for sketch_class in sketch_classes:\n",
    "    memory_usage[sketch_class.__name__] = get_sketch_size(sketch_class)\n",
    "\n",
    "# Plot memory usage\n",
    "plt.figure(figsize=(10, 6))\n",
    "sketch_names = list(memory_usage.keys())\n",
    "sizes = list(memory_usage.values())\n",
    "\n",
    "bars = plt.bar(sketch_names, sizes, color=['blue', 'orange', 'green', 'red'])\n",
    "plt.xlabel('Sketch Algorithm')\n",
    "plt.ylabel('Serialized Size (bytes)')\n",
    "plt.title('Memory Usage Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, sizes):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01, \n",
    "             f'{value}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMemory Usage (bytes):\")\n",
    "for name, size in memory_usage.items():\n",
    "    print(f\"{name}: {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the trade-offs between different sketch algorithms:\n",
    "\n",
    "- **HyperLogLog**: Good balance of accuracy and performance\n",
    "- **HyperLogLog++**: Improved accuracy for small cardinalities\n",
    "- **CPC**: Compressed representation with good accuracy\n",
    "- **Theta Sketch**: Set operations support with configurable accuracy\n",
    "\n",
    "Choose the algorithm based on your specific requirements for accuracy, performance, and memory usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}