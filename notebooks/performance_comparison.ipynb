{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Sketch Algorithms\n",
    "\n",
    "This notebook compares the performance and accuracy of different probabilistic data structures implemented in the sketches library."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import sketches\nimport numpy as np\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport time\nfrom collections import defaultdict"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison\n",
    "\n",
    "Let's compare the accuracy of different sketch algorithms across various cardinalities."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def test_accuracy(sketch_class, cardinalities, lg_k=12, k=4096):\n    results = []\n    \n    for n in cardinalities:\n        if 'Theta' in sketch_class.__name__:\n            sketch = sketch_class(k)\n        elif 'Cpc' in sketch_class.__name__:\n            sketch = sketch_class(lg_k)\n        else:\n            sketch = sketch_class(lg_k)\n            \n        # Add n unique elements\n        for i in range(n):\n            sketch.update(f\"item_{i}\")\n            \n        estimate = sketch.estimate()\n        error = abs(estimate - n) / n\n        results.append({'cardinality': n, 'estimate': estimate, 'error': error})\n        \n    return results"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test cardinalities\ncardinalities = [100, 500, 1000, 5000, 10000, 50000, 100000]\n\n# Test different sketch types\nsketch_classes = [\n    sketches.HllSketch,\n    sketches.CpcSketch,\n    sketches.ThetaSketch\n]\n\naccuracy_results = {}\nfor sketch_class in sketch_classes:\n    print(f\"Testing {sketch_class.__name__}...\")\n    accuracy_results[sketch_class.__name__] = test_accuracy(sketch_class, cardinalities)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Plot accuracy results\nplt.figure(figsize=(12, 8))\n\nfor sketch_name, results in accuracy_results.items():\n    df = pl.DataFrame(results)\n    cardinality_data = df['cardinality'].to_numpy()\n    error_data = df['error'].to_numpy()\n    plt.plot(cardinality_data, error_data, marker='o', label=sketch_name, linewidth=2)\n\nplt.xlabel('True Cardinality')\nplt.ylabel('Relative Error')\nplt.title('Accuracy Comparison of Sketch Algorithms')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xscale('log')\nplt.yscale('log')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Now let's compare the update performance of different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def benchmark_updates(sketch_class, n_updates=100000, lg_k=12, k=4096):\n    if 'Theta' in sketch_class.__name__:\n        sketch = sketch_class(k)\n    elif 'Cpc' in sketch_class.__name__:\n        sketch = sketch_class(lg_k)\n    else:\n        sketch = sketch_class(lg_k)\n    \n    start_time = time.time()\n    \n    for i in range(n_updates):\n        sketch.update(f\"item_{i}\")\n    \n    end_time = time.time()\n    \n    return {\n        'total_time': end_time - start_time,\n        'updates_per_second': n_updates / (end_time - start_time),\n        'estimate': sketch.estimate()\n    }"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Benchmark performance\nn_updates = 100000\nperformance_results = {}\n\nfor sketch_class in sketch_classes:\n    print(f\"Benchmarking {sketch_class.__name__}...\")\n    performance_results[sketch_class.__name__] = benchmark_updates(sketch_class, n_updates)\n\n# Display results\nperf_data = []\nfor name, results in performance_results.items():\n    perf_data.append({\n        'sketch': name,\n        'total_time': results['total_time'],\n        'updates_per_second': results['updates_per_second'],\n        'estimate': results['estimate']\n    })\n\nperf_df = pl.DataFrame(perf_data)\nprint(\"\\nPerformance Results:\")\nprint(perf_df)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sketch_names = list(performance_results.keys())\n",
    "updates_per_sec = [performance_results[name]['updates_per_second'] for name in sketch_names]\n",
    "\n",
    "bars = plt.bar(sketch_names, updates_per_sec, color=['blue', 'orange', 'green', 'red'])\n",
    "plt.xlabel('Sketch Algorithm')\n",
    "plt.ylabel('Updates per Second')\n",
    "plt.title('Performance Comparison: Updates per Second')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, updates_per_sec):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01, \n",
    "             f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage Comparison\n",
    "\n",
    "Let's compare the memory footprint of different sketch implementations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def get_sketch_size(sketch_class, lg_k=12, k=4096):\n    if 'Theta' in sketch_class.__name__:\n        sketch = sketch_class(k)\n    elif 'Cpc' in sketch_class.__name__:\n        sketch = sketch_class(lg_k)\n    else:\n        sketch = sketch_class(lg_k)\n    \n    # Add some data\n    for i in range(10000):\n        sketch.update(f\"item_{i}\")\n    \n    # Get serialized size as proxy for memory usage\n    # Note: ThetaSketch doesn't have to_bytes method, so we estimate size\n    if hasattr(sketch, 'to_bytes'):\n        serialized = sketch.to_bytes()\n        return len(serialized)\n    else:\n        # Estimate size for sketches without serialization\n        if 'Theta' in sketch_class.__name__:\n            return sketch.sample_capacity() * 8  # Rough estimate: 8 bytes per entry\n        else:\n            return 4096  # Default estimate\n\nmemory_usage = {}\nfor sketch_class in sketch_classes:\n    memory_usage[sketch_class.__name__] = get_sketch_size(sketch_class)\n\n# Plot memory usage\nplt.figure(figsize=(10, 6))\nsketch_names = list(memory_usage.keys())\nsizes = list(memory_usage.values())\n\nbars = plt.bar(sketch_names, sizes, color=['blue', 'orange', 'green'])\nplt.xlabel('Sketch Algorithm')\nplt.ylabel('Estimated Size (bytes)')\nplt.title('Memory Usage Comparison')\nplt.xticks(rotation=45)\n\n# Add value labels on bars\nfor bar, value in zip(bars, sizes):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01, \n             f'{value}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nMemory Usage (bytes):\")\nfor name, size in memory_usage.items():\n    print(f\"{name}: {size:,} bytes\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the trade-offs between different sketch algorithms:\n",
    "\n",
    "- **HyperLogLog**: Good balance of accuracy and performance\n",
    "- **HyperLogLog++**: Improved accuracy for small cardinalities\n",
    "- **CPC**: Compressed representation with good accuracy\n",
    "- **Theta Sketch**: Set operations support with configurable accuracy\n",
    "\n",
    "Choose the algorithm based on your specific requirements for accuracy, performance, and memory usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}