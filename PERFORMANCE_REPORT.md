# üöÄ Performance Benchmark Report

**Comprehensive comparison between our Rust-based sketches library and Apache DataSketches (official Python implementation)**

## Executive Summary

This report presents rigorous benchmarks comparing our Rust-based probabilistic data structures library with the official Apache DataSketches Python library. The tests were conducted using pytest-benchmark and custom performance measurement scripts to evaluate:

- **Processing Throughput** (items/second)
- **Memory Efficiency** (RAM usage) 
- **Estimation Accuracy** (error rates)
- **Serialization Performance** (speed and size)

## Test Environment

- **Platform**: macOS Darwin 23.6.0 (ARM64)
- **Rust**: 1.86.0
- **Python**: 3.12.5
- **Libraries Tested**:
  - Our library: `sketches` v0.1.6 (Rust + PyO3 bindings)
  - Comparison: `datasketches` v5.2.0 (Official Apache implementation)

## Benchmark Results

### üèÉ‚Äç‚ôÇÔ∏è Processing Throughput

**HyperLogLog Update Performance (2M items)**

| Implementation | Processing Time | Throughput | Speedup |
|---------------|----------------|------------|---------|
| **Apache DataSketches** | 0.29s | **7.1M items/sec** | **5.2x faster** |
| Our Library | 1.51s | 1.3M items/sec | baseline |

**Key Finding**: Apache DataSketches demonstrates superior raw throughput, processing ~5x more items per second.

### üíæ Memory Efficiency 

**HyperLogLog Memory Usage (1M unique items)**

| Implementation | Memory Usage | Memory Efficiency |
|---------------|-------------|------------------|
| **Apache DataSketches** | **32 KB** | **9x more efficient** |
| Our Library | 288 KB | baseline |

**Analysis**: Apache DataSketches uses significantly less memory, likely due to:
- Optimized C++ core with minimal Python overhead
- Advanced compression techniques
- More efficient data structures

### üéØ Estimation Accuracy

**HyperLogLog Error Rates Across Dataset Sizes**

| Dataset Size | True Count | Our Error | Apache Error | Winner |
|-------------|------------|-----------|--------------|--------|
| 1,000 | 1,000 | 0.22% | 0.72% | **Our Library** |
| 10,000 | 10,000 | 2.48% | **0.72%** | **Apache DataSketches** |
| 100,000 | 100,000 | 1.27% | **1.23%** | **Apache DataSketches** |
| 1,000,000 | 1,000,000 | 1.77% | **1.14%** | **Apache DataSketches** |

**Key Finding**: Both libraries achieve excellent accuracy (<3% error), with Apache DataSketches showing slightly better consistency across dataset sizes.

### üì¶ Serialization Performance

**HyperLogLog Serialized Size (100K items)**

| Implementation | Serialized Size | Compression Ratio |
|---------------|----------------|------------------|
| Apache DataSketches | TBD | TBD |
| Our Library | TBD | TBD |

*Note: Detailed serialization benchmarks pending*

## Detailed Analysis

### Strengths of Our Implementation

‚úÖ **Competitive Accuracy**: Achieves <3% error rates across all test sizes  
‚úÖ **Comprehensive Feature Set**: 18 total algorithms vs 9 in Apache DataSketches  
‚úÖ **Modern Architecture**: Rust memory safety + Python convenience  
‚úÖ **Rich API**: Advanced features like confidence bounds, statistics, merging  
‚úÖ **Better Small Dataset Accuracy**: 0.22% vs 0.72% error on 1K items  

### Strengths of Apache DataSketches

‚úÖ **Superior Performance**: 5x faster processing throughput  
‚úÖ **Memory Efficient**: 9x lower memory usage  
‚úÖ **Production Proven**: Battle-tested in enterprise environments  
‚úÖ **Optimized Implementation**: Highly tuned C++ core  
‚úÖ **Consistent Accuracy**: More stable error rates across dataset sizes  

### Performance Trade-offs

| Metric | Our Library | Apache DataSketches | Analysis |
|--------|-------------|-------------------|----------|
| **Raw Speed** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Apache DS optimized for pure performance |
| **Memory Usage** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Apache DS uses advanced compression |
| **Accuracy** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Both excellent, Apache DS slightly more consistent |
| **Feature Breadth** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Our library has 2x more algorithms |
| **API Richness** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | More statistical methods and utilities |
| **Memory Safety** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Rust eliminates entire classes of bugs |

## Use Case Recommendations

### Choose Our Library When:
- **Algorithm Diversity**: Need sampling, frequency estimation, or specialized sketches not in Apache DS
- **Memory Safety**: Rust guarantees eliminate segfaults and memory leaks
- **Rich Analytics**: Need advanced statistics, confidence bounds, merging operations
- **Modern Development**: Want type safety and excellent error messages
- **Custom Extensions**: Plan to extend or modify algorithms

### Choose Apache DataSketches When:
- **Pure Performance**: Maximum throughput is critical (5x faster)
- **Memory Constrained**: Running on resource-limited systems (9x less memory)
- **Production Scale**: Processing billions of items daily
- **Enterprise Integration**: Need proven stability and support
- **Simple Use Cases**: Basic cardinality estimation only

## Benchmark Methodology

### Test Data Generation
```python
def generate_test_data(size: int, unique_ratio: float = 1.0) -> List[str]:
    """Generate controlled test datasets with known cardinality"""
    unique_count = int(size * unique_ratio)
    return [f"item_{i:08d}" for i in range(unique_count)]
```

### Performance Measurement
- **Throughput**: Items processed per second using `time.perf_counter()`
- **Memory**: RSS measurement using `psutil.Process().memory_info()`
- **Accuracy**: Relative error as `|estimate - true| / true * 100`

### Benchmark Reproducibility
```bash
# Run Python benchmarks
pytest benchmarks/test_performance.py --benchmark-only

# Run Rust benchmarks  
cargo bench

# Quick validation
python benchmarks/test_performance.py quick
```

## Optimization Opportunities

### For Our Library
1. **SIMD Acceleration**: Implement AVX2/NEON optimizations for hash computations
2. **Memory Pooling**: Reduce allocation overhead in Python bindings
3. **Compression**: Add sparse representation and variable-length encoding
4. **Cache Optimization**: Improve data locality for better cache performance

### Algorithm-Specific Insights
- **HyperLogLog**: Consider HLL++ sparse representation for small cardinalities
- **Theta Sketches**: Optimize set operations with SIMD parallel processing  
- **Serialization**: Implement compact binary formats to match Apache DS efficiency

## Conclusion

Both libraries demonstrate excellent engineering for probabilistic data structures:

**Apache DataSketches** excels in **raw performance and memory efficiency**, making it ideal for high-throughput production environments where speed is paramount.

**Our Library** excels in **feature completeness and developer experience**, providing 2x more algorithms with modern Rust safety guarantees and richer analytics capabilities.

The choice depends on priorities:
- **Performance-critical applications**: Apache DataSketches
- **Feature-rich analytics**: Our library
- **Memory-constrained systems**: Apache DataSketches  
- **Comprehensive data science**: Our library

**Both achieve the fundamental goal**: enabling approximate analytics on massive datasets with bounded memory and excellent accuracy.

---

*This benchmark report represents performance characteristics as of December 2024. Performance may vary based on hardware, dataset characteristics, and usage patterns. For production deployments, conduct application-specific benchmarks.*